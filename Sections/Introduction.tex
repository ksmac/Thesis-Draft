%For centuries, philosophers and physicists have delved into the idea of what constructs and drive living beings including, in the grand scale, the universe as we know it. From the development of classical mechanics by the likes of Galileo Galilei and Sir Isaac Newton in the 17th Century, to the discovery and fundamental establishment of electromagnetism in the 19th Century by the likes of Michael Faraday, André-Marie Ampère, Hans Christian Ørsted, and James Maxwell, physicists have achieved a phenomenal feet throughout modern history. These establishments became building blocks and in the 20th Century society witnessed further advancements. In particular, the foundations of the connection between quantum mechanics and particle physics were built by the likes of Emmy Noether (Noether's theorem for conservation laws), Richard Feynman (Quantum Electrodynamics and Feynman diagrams), Hideki Yukawa (Yukawa coupling). We have started to quantize nature to reach a deeper understanding, and the particle physics community established fundamental properties to matter and forces entering the 21st Century.  \\

Fast forward to July 2012, the world received the news of the discovery of the Higgs Boson through experiments at the Large Hadron Collider (LHC) \cite{chatrchyan2012observation,aad2012observation}. The discovery completed the extent of the Standard Model (SM) as we know it, where three of the fundamental forces - strong, weak and electromagnetism - are well encapsulated giving a firm ground to the three generations of fundamental particles in quarks and leptons. However, the SM itself is an incomplete theory. This stems from the fact that the other fundamental force, gravity, remains unanswered at the quantum scale and how it contributes to the elementary particles. Unifying all four forces was Albert Einstein's dream, and remains a goal for physicists of the present and future. Another reason is due to 'dark matter' not being observed directly at the elementary particle scale yet, despite accounting for roughly $25\% $ of the universe's critical density \cite{bahcall2015dark}. There are many more problems such as the hierarchy problem, the neutrino mass problem and the need for three generations of fundamental particles and so on, that could be expanded upon depending on the field of interest. \par

%This stems from the fact that the observed mass of $ m_H \approx 125\text{GeV} $ of the Higgs Boson is 'too light'. This is known as the gauge hierarchy problem \cite{martin1997supersymmetry}, where the squared Higgs mass ($ m^2_T $) requires quantum corrections from invisible (virtual) particles and fields to reach the minimum value. \par

A proposed solution to these issues is Supersymmetry (SUSY), where so-called super-partners of the SM particles are introduced. These super-partners are initially theorized to be of equal mass to the SM counterparts. However, the experimental endeavor for such particles disproves that, leading us to the understanding that they must be extremely heavy. Furthermore, SUSY predicts a symmetry-breaking in a way that allows the observed Higgs mass to be valid. It is also predicted that, electromagnetism, strong, and the weak force would still hold in high energy scales that correspond to the early universe just after the Big Bang. Quantum gravity is accounted for at the Plank scale $ M_p = (8\pi G_{\text{Newton}})^{-1/2} = 2.4 \times 10^{18} \text{GeV} $, although it is much larger than the electroweak scale \cite{martin1997supersymmetry}, hence making it a difficult task to sought out not only gravity but the super-partners as well. If SUSY turns out to be a successful model, then it signifies the high energy physics community is heading toward the right direction to formulate the Grand Unifying theory - where all four fundamental forces are united mathematically. \\

%To test the correctness of SUSY, further experiments have been conducted at the LHC in the quest to find said superparticles. This seems to be a dead-end to high energy physicists as none of the theorized phenomena nor particles from SUSY have been observed directly, despite the upgrade in the collider's energy levels. 
Since the search for phenomena beyond SM has proven to be difficult, the most obvious solution is to produce collisions at a much higher center-of-mass ($\sqrt{s}$) energy than what the LHC currently produces (13TeV). This is problematic as building a much larger facility is unavoidable if physicists were to pursue this route. Instead, the sensitivity and signal selection to SUSY can be achieved with the current resource available. With an upgrade to the High-Luminosity LHC set to be ready by 2026 \cite{apollinari2015high, apollinari2017high} which will see the collision rate of protons increased by a factor of 10, there is hope that the increased amount of data improves the sensitivity of the searches for SUSY. \\

Machine Learning comes into play here in particular for signal selection. Machine learning has made a significant impact in the past few decades not only in scientific areas but also in industry. The emergence of 'Big Data' accumulated over the years has allowed the refinement of machine learning models and increased its reliability in real-world applications. The Higgs Boson was discovered with the help of machine learning \cite{chatrchyan2012observation,aad2012observation}. High energy physics has been a frontier to employing machine learning techniques and is essentially a gold mine for data scientists. A fraction of the available data is made public partly due to its sheer size. To give a sense of how large the produced data is, CERN has a self-established network across the globe dedicated to handling the 25 petabytes (initially 15 \cite{shiers2007worldwide}) of data produced a year known as the Worldwide LHC Computing Grid (WLCG), which is said to be the largest in the world. Since $1\text{PB} = 10^6\text{GB}$, it is easy to see that this is a massive amount of data, requiring $10^5$ computers to operate through such amount at the time of proposal \cite{shiers2007worldwide} (it would be roughly $10^3$ now as a decent computer would have 1TB = 1000GB of storage space available). With the evolution of machine learning and the endless supply of data produced by the LHC, a more complete and systematic study for refinements in SM and SUSY both experimentally and theoretically.\\

The following sections will introduce some basic concepts to understand the key areas of the standard model and SUSY required for the project. Subsequent sections will introduce approaches and concepts necessary for the project, such as the methods of searching for SUSY (in particle, the Minimum Supersymmetric Standard Model i.e. MSSM), the decay channel of stops and basic concepts and research applications of machine learning algorithms.